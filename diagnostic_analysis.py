"""
Compute summary statistics from the simulated data produced by `test_topmoc_100_1.py`.
Some output data are used for Table 1.
However, many other output data are not used in the manuscript. They are only for diagnosis.

Usage:

    python diagnostic_analysis.py all_runs_result_X.csv

    X depends on the dynamics.
    I renamed `all_runs_result.csv` generated by test_topmoc_100_1.py with trials=100 and dynamics={1,2,3,4,5,6,7,8,9} to `all_runs_result_X.csv`, where X is the name of the dynamical system.

Output:

    Results returned on the terminal are used for populating Table 1.
    
    This code also returns some diagnostic figures and more statistics, but they are not used in the manuscript.
"""

import argparse
import sys
import os
import re
from itertools import combinations

import numpy as np
import pandas as pd
from scipy import stats
import seaborn as sns
import matplotlib.pyplot as plt


def parse_args():
    p = argparse.ArgumentParser(description="Diagnostic comparisons and pairwise correlations.")
    p.add_argument("csvfile", help="Path to input CSV file")
    p.add_argument("--out-prefix", default="results", help="Prefix for output figures (default: results)")
    return p.parse_args()


def to_bool_like(x):
    """Robustly map typical True/False string/boolean values to Python bool, otherwise np.nan."""
    if pd.isnull(x):
        return np.nan
    s = str(x).strip().lower()
    if s in ("true", "t", "1", "yes", "y"):
        return True
    if s in ("false", "f", "0", "no", "n"):
        return False
    return np.nan


def fraction_true(df, col="detected_AIC"):
    detected_bool = df[col].apply(to_bool_like)
    n_total = len(df)
    # count True (sum of booleans) ignoring NaNs
    n_true = int(detected_bool.sum(skipna=True)) if not detected_bool.isnull().all() else 0
    frac = n_true / n_total if n_total > 0 else np.nan
    return frac, n_true, n_total, detected_bool


def compare_tau(df, detected_bool, value_col="tau", alpha=0.05):
    """
    Compare value_col between rows where detected_bool==True and detected_bool==False.
    Selects test based on normality and variance equality:
      - If approx normal in both groups -> t-test (Student or Welch depending on Levene)
      - Otherwise -> Mann-Whitney U (nonparametric)
    """
    vals = pd.to_numeric(df[value_col], errors="coerce")
    mask_true = detected_bool == True
    mask_false = detected_bool == False

    x = vals[mask_true].dropna().astype(float).values
    y = vals[mask_false].dropna().astype(float).values

    res = {"n_true": len(x), "n_false": len(y)}

    print("\n--- Tau comparison ---")
    if len(x) > 0:
        print(f"Group True: n = {len(x)}, mean = {np.mean(x):.4f}, sd = {np.std(x, ddof=1):.4f}")
    else:
        print("Group True: n = 0")
    if len(y) > 0:
        print(f"Group False: n = {len(y)}, mean = {np.mean(y):.4f}, sd = {np.std(y, ddof=1):.4f}")
    else:
        print("Group False: n = 0")

    if len(x) == 0 or len(y) == 0:
        print("One of the groups is empty; statistical comparison is not possible.")
        res["note"] = "one_group_empty"
        return res

    # Normality tests (Shapiro-Wilk) only if sample size >= 3
    shapiro_x = shapiro_y = None
    normal_x = normal_y = None
    if len(x) >= 3:
        shapiro_x = stats.shapiro(x)
        normal_x = shapiro_x.pvalue > alpha
        print(f"Shapiro-Wilk (True): W={shapiro_x.statistic:.4f}, p={shapiro_x.pvalue:.4e} -> normal? {normal_x}")
    else:
        print("Shapiro-Wilk (True): not enough samples (<3) to test normality")
    if len(y) >= 3:
        shapiro_y = stats.shapiro(y)
        normal_y = shapiro_y.pvalue > alpha
        print(f"Shapiro-Wilk (False): W={shapiro_y.statistic:.4f}, p={shapiro_y.pvalue:.4e} -> normal? {normal_y}")
    else:
        print("Shapiro-Wilk (False): not enough samples (<3) to test normality")

    # Variance equality test: Levene
    levene_res = None
    equal_var = None
    if len(x) >= 2 and len(y) >= 2:
        levene_res = stats.levene(x, y, center="median")
        equal_var = levene_res.pvalue > alpha
        print(f"Levene test (median center): W={levene_res.statistic:.4f}, p={levene_res.pvalue:.4e} -> equal variances? {equal_var}")
    else:
        print("Levene test: not enough samples (<2 in one group) to test variance equality")

    both_normal = (normal_x is True) and (normal_y is True)

    if both_normal:
        use_equal_var = True if equal_var is True else False
        tstat, pval = stats.ttest_ind(x, y, equal_var=use_equal_var, nan_policy="omit")
        test_name = "Student t-test (equal variances)" if use_equal_var else "Welch t-test (unequal variances)"
        # Effect size Cohen's d
        m1, m2 = np.mean(x), np.mean(y)
        s1, s2 = np.std(x, ddof=1), np.std(y, ddof=1)
        n1, n2 = len(x), len(y)
        if use_equal_var and (n1 + n2 - 2) > 0:
            pooled_sd = np.sqrt(((n1 - 1) * s1 ** 2 + (n2 - 1) * s2 ** 2) / (n1 + n2 - 2))
            cohens_d = (m1 - m2) / pooled_sd if pooled_sd > 0 else np.nan
        else:
            pooled_sd = np.sqrt((s1 ** 2 + s2 ** 2) / 2)
            cohens_d = (m1 - m2) / pooled_sd if pooled_sd > 0 else np.nan
        print(f"\n{test_name}: t = {tstat:.4f}, p = {pval:.4e}")
        print(f"Mean(True) = {m1:.4f}, Mean(False) = {m2:.4f}, Cohen's d ~= {cohens_d:.4f}")
        res.update({
            "test": test_name,
            "t_stat": float(tstat),
            "p_value": float(pval),
            "cohen_d": float(cohens_d),
            "mean_true": float(m1),
            "mean_false": float(m2),
            "sd_true": float(s1),
            "sd_false": float(s2),
        })
    else:
        # Nonparametric: Mann-Whitney U
        try:
            u_stat, pval = stats.mannwhitneyu(x, y, alternative="two-sided")
            n1, n2 = len(x), len(y)
            mean_u = n1 * n2 / 2.0
            sd_u = np.sqrt(n1 * n2 * (n1 + n2 + 1) / 12.0)
            if sd_u > 0:
                z = (u_stat - mean_u) / sd_u
                r_effect = z / np.sqrt(n1 + n2)
            else:
                z = np.nan
                r_effect = np.nan
            print(f"\nMann-Whitney U: U = {u_stat:.4f}, p = {pval:.4e}")
            print(f"Approx z = {z:.4f}, effect-size r ~= {r_effect:.4f}")
            res.update({
                "test": "Mann-Whitney U",
                "u_stat": float(u_stat),
                "p_value": float(pval),
                "z": float(z) if not np.isnan(z) else None,
                "r_effect": float(r_effect) if not np.isnan(r_effect) else None,
                "mean_true": float(np.mean(x)),
                "mean_false": float(np.mean(y)),
            })
        except Exception as e:
            print("Mann-Whitney U test failed:", str(e))
            res["note"] = "mannwhitney_failed"
    return res


def pairwise_correlation_and_plots(df, detected_bool, csvfile=None, out_prefix="results"):
    """
    For rows with detected_bool == True, compute pairwise Pearson correlations among selected columns
    and create two output PNG files:
      - pairplot_<suffix>.png
      - corr_heatmap_<suffix>.png
    where <suffix> = X if csvfile basename is ews_result_X.csv, otherwise basename without extension.
    """
    vars_sel = [
        "tau",
        "c_at_detection", # u_{det}
        "rdiv_at_detection", # \hat{u}_c
        "gamma_at_detection",
        "best_corr_at_detection",
    ]

    df_true = df[detected_bool == True].copy()
    if df_true.empty:
        print("\nNo rows with detected_AIC == True; skipping correlation analysis.")
        return None

    df_num = df_true[vars_sel].apply(pd.to_numeric, errors="coerce")
    df_plot = df_num.dropna()

    # Determine output filenames based on csvfile
    if csvfile:
        base = os.path.basename(csvfile)
        m = re.match(r"^ews_result_(.+)\.csv$", base, flags=re.IGNORECASE)
        if m:
            suffix = m.group(1)
            pairplot_fn = f"pairplot_{suffix}.png"
            hm_fn = f"corr_heatmap_{suffix}.png"
        else:
            prefix = os.path.splitext(base)[0]
            pairplot_fn = f"pairplot_{prefix}.png"
            hm_fn = f"corr_heatmap_{prefix}.png"
    else:
        pairplot_fn = f"{out_prefix}_pairplot_true.png"
        hm_fn = f"{out_prefix}_corr_heatmap_true.png"

    print(f"\nUsing {len(df_plot)} rows (from {len(df_true)} True rows) with complete data for pairwise correlations/plots.")

    # Pairwise Pearson (pairwise-complete)
    print("\nPairwise Pearson correlations (r and p-value) computed pairwise on available pairs:")
    pair_results = []
    for a, b in combinations(vars_sel, 2):
        pair_df = df_num[[a, b]].dropna()
        if len(pair_df) < 2:
            print(f"{a} vs {b}: not enough paired observations (n={len(pair_df)})")
            pair_results.append((a, b, np.nan, np.nan, len(pair_df)))
            continue
        try:
            r, p = stats.pearsonr(pair_df[a].values, pair_df[b].values)
            print(f"{a} vs {b}: n={len(pair_df)}, r = {r:.4f}, p = {p:.4e}")
            pair_results.append((a, b, float(r), float(p), len(pair_df)))
        except Exception as e:
            print(f"{a} vs {b}: pearsonr failed ({e}); n={len(pair_df)}")
            pair_results.append((a, b, np.nan, np.nan, len(pair_df)))

    corr_matrix = df_num.corr(method="pearson")
    print("\nCorrelation matrix (pairwise-complete):")
    print(corr_matrix.round(4))

    # Create pairplot-like figure if we have at least 2 complete rows
    if df_plot.shape[0] >= 2:
        sns.set(style="white")
        g = sns.PairGrid(df_plot, vars=vars_sel, diag_sharey=False)

        # lower: scatter + regression line
        g.map_lower(sns.scatterplot, s=25, edgecolor="k", linewidth=0.2)

        def reg_on_lower(x, y, **kwargs):
            ax = plt.gca()
            try:
                sns.regplot(x=x, y=y, scatter=False, ax=ax, line_kws={"color": "red"}, ci=None)
            except Exception:
                pass

        g.map_lower(reg_on_lower)

        # diagonal: histogram + KDE
        g.map_diag(sns.histplot, kde=True, bins=20)

        # upper: annotate Pearson r and p
        def annotate_corr(x, y, **kws):
            ax = plt.gca()
            try:
                r, p = stats.pearsonr(x, y)
                txt = f"r = {r:.3f}\np = {p:.3f}"
            except Exception:
                txt = "n<2 or constant"
            ax.annotate(txt, xy=(0.5, 0.5), xycoords=ax.transAxes, ha="center", va="center", fontsize=10)

        g.map_upper(annotate_corr)

        plt.subplots_adjust(top=0.95)
        g.fig.suptitle("Pairwise scatter plots + Pearson r (True rows, complete cases)", fontsize=14)
        g.fig.set_size_inches(12, 12)
        g.savefig(pairplot_fn, dpi=150)
        print(f"\nPairwise scatter-grid saved to: {pairplot_fn}")
        plt.close(g.fig)
    else:
        print("Not enough complete cases to produce PairGrid plot (need >= 2 complete rows).")

    # Heatmap of the correlation matrix (pairwise-complete)
    try:
        plt.figure(figsize=(8, 6))
        sns.heatmap(corr_matrix, annot=True, fmt=".3f", cmap="coolwarm", center=0, square=False)
        plt.title("Pearson correlation matrix (True rows, pairwise-complete)")
        plt.tight_layout()
        plt.savefig(hm_fn, dpi=150)
        plt.close()
        print(f"Correlation heatmap saved to: {hm_fn}")
    except Exception as e:
        print("Failed to produce heatmap:", str(e))

    return {"pairwise": pair_results, "corr_matrix": corr_matrix}

def analyze_hatuc(df, u_init=0.0, u_c=3.079):
    """
    Compute stats for hat{u}_c and calculate the fraction 
    of runs within the specified u_c range.
    """
    print("\n--- hatuc Analysis ---")
    
    # Ensure numeric and drop NaNs
    hatuc = pd.to_numeric(df['rdiv_at_detection'], errors='coerce').dropna()
    
    if hatuc.empty:
        print("No valid hat{u}_c data found.")
        return

    # Calculate basic stats
    mean_val = hatuc.mean()
    std_val = hatuc.std(ddof=1)
    median_val = hatuc.median()
    p10 = hatuc.quantile(0.10)
    p90 = hatuc.quantile(0.90)

    print(f"Mean hatuc:   {mean_val:.4f}")
    print(f"SD hatuc:     {std_val:.4f}")
    print(f"Median hatuc: {median_val:.4f}")
    print(f"10th Percentile: {p10:.4f}")
    print(f"90th Percentile: {p90:.4f}")

    # Calculate fraction within range
    # Range: u_c Â± 0.1 * (u_c - u_init)
    delta = 0.1 * (u_c - u_init)
    lower_bound = u_c - delta
    upper_bound = u_c + delta
    
    in_range = hatuc[(hatuc >= lower_bound) & (hatuc <= upper_bound)]
    fraction = len(in_range) / len(hatuc)

    print(f"\nRange check (u_init={u_init}, u_c={u_c}):")
    print(f"Target Range: [{lower_bound:.4f}, {upper_bound:.4f}]")
    print(f"Fraction of runs in range: {fraction:.4f} ({len(in_range)}/{len(hatuc)})")

# start of main
args = parse_args()
csvfile = args.csvfile
out_prefix = args.out_prefix

try:
    df = pd.read_csv(csvfile)
except Exception as e:
    print(f"Error reading CSV file {csvfile}: {e}")
    sys.exit(1)

tau_vals = pd.to_numeric(df['tau'], errors='coerce').dropna()
if not tau_vals.empty:
    print(f"\n--- Task 0: Overall Tau Statistics ---")
    print(f"Mean tau: {tau_vals.mean():.4f}")
    print(f"SD tau:   {tau_vals.std(ddof=1):.4f}")
    print(f"N:        {len(tau_vals)}")

# fraction of True in 3rd column (detected_AIC)
frac, n_true, n_total, detected_bool = fraction_true(df, col="detected")
print(f"\nFraction Detected: {frac:.4f} ({n_true}/{n_total})")

# compare tau between True and False
_ = compare_tau(df, detected_bool, value_col="tau")

# pairwise Pearson correlations and plots for rows with True
_ = pairwise_correlation_and_plots(df, detected_bool, csvfile=csvfile, out_prefix=out_prefix)

dynamics = 1
if dynamics==1 or dynamics==2 or dynamics==3: # double-well
    analyze_hatuc(df, u_init=0.0, u_c=3.079)
elif dynamics==4: # over-harvesting with K=10, showing saddle-node bifurcationo
    analyze_hatuc(df, u_init=1.0, u_c=2.604)
elif dynamics==5: # linear grazing
    analyze_hatuc(df, u_init=0.0, u_c=1.0)
elif dynamics==6: # Rosenzweig-MacArthur
    analyze_hatuc(df, u_init=1.1, u_c=2.6)
elif dynamics==7: # mutualistic-interaction
    analyze_hatuc(df, u_init=-1.0, u_c=-0.047)
elif dynamics==8 or dynamics==9: # over-harvesting with K=2 or OU. They do not show a bifurcation, so dummy values are filled.
    analyze_hatuc(df, u_init=0.0, u_c=1.0)